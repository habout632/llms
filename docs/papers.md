# LLM

## GPT

### GPT2
[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

### GPT3
[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)

### GPT4
[GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf)


## LLama

### LLama 1&2 


### LLama 3.1
[The Llama 3 Herd of Models](https://arxiv.org/pdf/2407.21783)


## Phi3
技术要点

[Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219)


### Dataset

open dataset on the web：具体用的什么也没提
synthetic dataset: 没有提到如何合成的


### Pretrain

#### 详细的参数列表

#### 技术点汇总

LongRoPE:不需要重新训练 就可以将context window扩大到128k技术  

muP:在小规模模型获得的hyperparameters 迁移到大规模模型中

GELU > GEGLU > ReGLU > SwiGLU


### SFT

### RLHF

### Evaluation Benchmarks




## Gemma2

[Gemma 2: Improving Open Language Models at a Practical Size](https://arxiv.org/pdf/2408.00118)


## Mistral

## Qwen2
[Qwen Technical Report](https://arxiv.org/pdf/2309.16609)
[Qwen2 Technical Report](https://arxiv.org/abs/2407.10671)

llm用到的dataset一般都没有公开


## GLM4
[]()
[]()
[]()
[]()

## Claude 
[The Claude 3 Model Family: Opus, Sonnet, Haiku](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)

# VLM

## Florence2

## LLaVA

## MiniCPM

## Qwen2-VL

[Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](https://arxiv.org/pdf/2308.12966)
[Qwen2-VL Technical Report](https://qwenlm.github.io/blog/qwen2-vl/)


## CogVLM2

[CogVLM2: Visual Language Models for Image and Video Understanding](https://arxiv.org/pdf/2408.16500)







